#!/usr/bin/env python3
"""
Certificate Generator Dashboard v2
- Browse Google Drive folders
- Select sheets from folder
- Auto-trigger when new names added
- Multiple variables support
"""

import eventlet
eventlet.monkey_patch()

from flask import Flask, render_template, jsonify, request
from flask_socketio import SocketIO, emit
import threading
import time
import re
import json
import os
import glob
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io

app = Flask(__name__)
app.config['SECRET_KEY'] = 'certificate-generator-secret'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='eventlet')

# ============ STATE ============
state = {
    'status': 'idle',  # idle, running, paused, completed, watching
    'total': 0,
    'completed': 0,
    'failed': 0,
    'current_name': '',
    'start_time': None,
    'logs': [],
    'retry_count': 0,  # Current retry attempt
    'max_retries': 1,  # Maximum number of retry attempts
    
    # Configuration
    'config': {
        'template_doc_url': '',
        'template_doc_id': '',
        'template_doc_name': '',
        'target_folder_url': '',
        'target_folder_id': '',
        'target_folder_name': '',
        'temp_folder_url': '',
        'temp_folder_id': '',
        'temp_folder_name': '',
        'sheet_url': '',
        'sheet_id': '',
        'sheet_name': '',
        'range_mode': 'all',  # 'all' or 'custom'
        'range_start': 2,
        'range_end': 1000,
        'link_column': 'O',
        'name_column': '',  # Auto-detected column with name
        'auto_watch': False,
        'watch_interval': 30,  # seconds
        'cleanup': {
            'enabled': True,
            'remove_words': [
                'ÿßÿ≥ÿ™ÿßÿ∞', 'ÿßÿ≥ÿ™ÿßÿ∞Ÿá', 'ÿßÿ≥ÿ™ÿßÿ∞ÿ©', 'ÿ£ÿ≥ÿ™ÿßÿ∞', 'ÿ£ÿ≥ÿ™ÿßÿ∞Ÿá', 'ÿ£ÿ≥ÿ™ÿßÿ∞ÿ©',
                'ÿß.', 'ÿ£.', 'ÿß/', 'ÿ£/',
                'ÿØŸÉÿ™Ÿàÿ±', 'ÿØŸÉÿ™Ÿàÿ±Ÿá', 'ÿØŸÉÿ™Ÿàÿ±ÿ©', 'ÿØ.', 'ÿØ/', 'Dr', 'Dr.',
                'ŸÖÿ≠ÿßŸÖŸä', 'ŸÖÿ≠ÿßŸÖŸäŸá', 'ŸÖÿ≠ÿßŸÖŸäÿ©', 'ŸÖ.', 'ŸÖ/',
                'ŸÖŸáŸÜÿØÿ≥', 'ŸÖŸáŸÜÿØÿ≥Ÿá', 'ŸÖŸáŸÜÿØÿ≥ÿ©', 'Eng', 'Eng.',
                'ÿßŸÑŸÖŸáŸÜÿØÿ≥', 'ÿßŸÑŸÖŸáŸÜÿØÿ≥Ÿá', 'ÿßŸÑŸÖŸáŸÜÿØÿ≥ÿ©', 'ÿßŸÑÿØŸÉÿ™Ÿàÿ±', 'ÿßŸÑÿØŸÉÿ™Ÿàÿ±Ÿá', 'ÿßŸÑÿØŸÉÿ™Ÿàÿ±ÿ©',
                'ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞', 'ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞Ÿá', 'ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞ÿ©', 'ÿßŸÑÿßÿ≥ÿ™ÿßÿ∞', 'ÿßŸÑÿßÿ≥ÿ™ÿßÿ∞Ÿá', 'ÿßŸÑÿßÿ≥ÿ™ÿßÿ∞ÿ©',
                'ÿßŸÑŸÖÿ≠ÿßŸÖŸä', 'ÿßŸÑŸÖÿ≠ÿßŸÖŸäŸá', 'ÿßŸÑŸÖÿ≠ÿßŸÖŸäÿ©',
                'ÿ≥ŸäÿØ', 'ÿ≥ŸäÿØŸá', 'ÿ≥ŸäÿØÿ©', 'ÿßŸÑÿ≥ŸäÿØ', 'ÿßŸÑÿ≥ŸäÿØŸá', 'ÿßŸÑÿ≥ŸäÿØÿ©',
                'ÿ¥ŸäÿÆ', 'ÿßŸÑÿ¥ŸäÿÆ',
                'ÿ≠ÿßÿ¨', 'ÿ≠ÿßÿ¨Ÿá', 'ÿ≠ÿßÿ¨ÿ©', 'ÿßŸÑÿ≠ÿßÿ¨', 'ÿßŸÑÿ≠ÿßÿ¨Ÿá', 'ÿßŸÑÿ≠ÿßÿ¨ÿ©',
                'ÿπŸÖŸäÿØ', 'ÿßŸÑÿπŸÖŸäÿØ',
                'ŸÑŸàÿßÿ°', 'ÿßŸÑŸÑŸàÿßÿ°',
                'ÿπŸÇŸäÿØ', 'ÿßŸÑÿπŸÇŸäÿØ',
                'ÿ±ÿßÿ¶ÿØ', 'ÿßŸÑÿ±ÿßÿ¶ÿØ',
                'ŸÜŸÇŸäÿ®', 'ÿßŸÑŸÜŸÇŸäÿ®',
                'ŸÖŸÑÿßÿ≤ŸÖ', 'ÿßŸÑŸÖŸÑÿßÿ≤ŸÖ',
                'ŸÖÿ≥ÿ™ÿ¥ÿßÿ±', 'ŸÖÿ≥ÿ™ÿ¥ÿßÿ±Ÿá', 'ŸÖÿ≥ÿ™ÿ¥ÿßÿ±ÿ©', 'ÿßŸÑŸÖÿ≥ÿ™ÿ¥ÿßÿ±', 'ÿßŸÑŸÖÿ≥ÿ™ÿ¥ÿßÿ±Ÿá', 'ÿßŸÑŸÖÿ≥ÿ™ÿ¥ÿßÿ±ÿ©',
                'ŸÇÿßÿ∂Ÿä', 'ÿßŸÑŸÇÿßÿ∂Ÿä',
                'ŸÉÿßÿ®ÿ™ŸÜ', 'ÿßŸÑŸÉÿßÿ®ÿ™ŸÜ', 'Captain', 'Capt',
                'ÿ®ÿ±ŸàŸÅŸäÿ≥Ÿàÿ±', 'ÿ®ÿ±ŸàŸÅÿ≥Ÿàÿ±', 'Prof', 'Prof.',
                'Mr', 'Mr.', 'Mrs', 'Mrs.', 'Ms', 'Ms.', 'Miss',
                'Sir', 'Madam'
            ],
            'remove_before_slash': True,
            'remove_alef': True,
            'trim_spaces': True
        }
    },
    
    # Available sheets in folder
    'available_sheets': [],
    
    # Sheet columns (from header row)
    'columns': [],
    
    # Variables
    'variables': [],
    
    # Service accounts
    'accounts': [],
    'accounts_loaded': False,
    
    # Processed names (to detect new ones)
    'processed_names': set(),
}

# Threading control
generator_thread = None
watcher_thread = None
stop_flag = threading.Event()
pause_flag = threading.Event()
watch_stop_flag = threading.Event()

SCOPES = ['https://www.googleapis.com/auth/drive', 
          'https://www.googleapis.com/auth/documents',
          'https://www.googleapis.com/auth/presentations',
          'https://www.googleapis.com/auth/spreadsheets']

# ============ HELPERS ============

def extract_id_from_url(url):
    """Extract Google Drive/Docs/Sheets ID from URL"""
    if not url:
        return ''
    
    if '/' not in url and len(url) > 20:
        return url
    
    patterns = [
        r'/d/([a-zA-Z0-9_-]+)',
        r'/folders/([a-zA-Z0-9_-]+)',
        r'/spreadsheets/d/([a-zA-Z0-9_-]+)',
        r'id=([a-zA-Z0-9_-]+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    return url

def column_to_index(col):
    """Convert column letter to 0-based index (handles upper/lower case)"""
    col = col.strip().upper()
    result = 0
    for char in col:
        if char.isalpha():
            result = result * 26 + (ord(char) - ord('A') + 1)
    return result - 1 if result > 0 else 0

def clean_name(name):
    """Clean name by removing titles and prefixes"""
    cleanup = state['config'].get('cleanup', {})
    
    if not cleanup.get('enabled', True):
        return name
    
    cleaned = name
    
    # Remove everything before /
    if cleanup.get('remove_before_slash', True) and '/' in cleaned:
        cleaned = cleaned.split('/')[-1]
    
    # Get words to remove
    words = cleanup.get('remove_words', [])
    
    # Sort by length (longest first) to avoid partial matches
    words_sorted = sorted(words, key=len, reverse=True)
    
    # Remove each word from the beginning
    for word in words_sorted:
        pattern = r'^\s*' + re.escape(word) + r'\s*'
        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
    
    # Remove standalone alef at start (ÿß or ÿ£ followed by space)
    if cleanup.get('remove_alef', True):
        cleaned = re.sub(r'^[ÿßÿ£]\s+', '', cleaned)
    
    # Trim spaces
    if cleanup.get('trim_spaces', True):
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    
    return cleaned

# Lock for thread-safe state updates
state_lock = threading.Lock()

def add_log(message, level='info'):
    """Add log message and broadcast"""
    timestamp = time.strftime('%H:%M:%S')
    log_entry = {'time': timestamp, 'message': message, 'level': level}
    
    with state_lock:
        state['logs'].append(log_entry)
        if len(state['logs']) > 500:
            state['logs'] = state['logs'][-500:]
    
    try:
        socketio.emit('log', log_entry, namespace='/')
    except:
        pass

def broadcast_state():
    """Send current state to all clients"""
    try:
        with state_lock:
            data = {
                'status': state['status'],
                'total': state['total'],
                'completed': state['completed'],
                'failed': state['failed'],
                'current_name': state['current_name'],
                'elapsed': time.time() - state['start_time'] if state['start_time'] else 0,
                'rate': state['completed'] / ((time.time() - state['start_time']) / 60) if state['start_time'] and time.time() > state['start_time'] else 0,
                'watching': state['config']['auto_watch'],
            }
        socketio.emit('state_update', data, namespace='/')
    except:
        pass

def load_service_accounts():
    """Load all service account JSON files"""
    state['accounts'] = []
    
    sa_patterns = ['saedny-*.json', 'service-account-*.json', 'sa-*.json']
    sa_files = []
    
    for pattern in sa_patterns:
        sa_files.extend(glob.glob(pattern))
    
    sa_files = sorted(set(sa_files))
    
    if not sa_files:
        add_log('‚ö†Ô∏è No service account files found!', 'error')
        return False
    
    for f in sa_files:
        try:
            creds = service_account.Credentials.from_service_account_file(f, scopes=SCOPES)
            state['accounts'].append({'file': f, 'creds': creds})
            add_log(f'‚úì Loaded: {f}', 'success')
        except Exception as e:
            add_log(f'‚úó Failed to load {f}: {e}', 'error')
    
    state['accounts_loaded'] = True
    add_log(f'üìä Loaded {len(state["accounts"])} service accounts', 'info')
    return len(state['accounts']) > 0

def get_services(acc_idx=0):
    """Get API services for an account"""
    if not state['accounts']:
        load_service_accounts()
    if not state['accounts']:
        return None, None, None, None
    
    creds = state['accounts'][acc_idx % len(state['accounts'])]['creds']
    return (
        build('drive', 'v3', credentials=creds, cache_discovery=False),
        build('docs', 'v1', credentials=creds, cache_discovery=False),
        build('slides', 'v1', credentials=creds, cache_discovery=False),
        build('sheets', 'v4', credentials=creds, cache_discovery=False)
    )

# ============ FOLDER BROWSING ============

def list_sheets_in_folder(folder_id):
    """List all Google Sheets in a folder"""
    drive, _, _, _ = get_services(0)
    if not drive:
        return []
    
    try:
        results = drive.files().list(
            q=f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.spreadsheet' and trashed=false",
            fields="files(id, name, modifiedTime)",
            orderBy="modifiedTime desc",
            supportsAllDrives=True,
            includeItemsFromAllDrives=True
        ).execute()
        
        return results.get('files', [])
    except Exception as e:
        add_log(f'‚ùå Error listing folder: {e}', 'error')
        return []

def list_folder_contents(folder_id):
    """List folders and sheets in a folder"""
    drive, _, _, _ = get_services(0)
    if not drive:
        return {'folders': [], 'sheets': []}
    
    try:
        # Get folders
        folders_result = drive.files().list(
            q=f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false",
            fields="files(id, name)",
            orderBy="name",
            supportsAllDrives=True,
            includeItemsFromAllDrives=True
        ).execute()
        
        # Get sheets
        sheets_result = drive.files().list(
            q=f"'{folder_id}' in parents and mimeType='application/vnd.google-apps.spreadsheet' and trashed=false",
            fields="files(id, name, modifiedTime)",
            orderBy="modifiedTime desc",
            supportsAllDrives=True,
            includeItemsFromAllDrives=True
        ).execute()
        
        return {
            'folders': folders_result.get('files', []),
            'sheets': sheets_result.get('files', [])
        }
    except Exception as e:
        add_log(f'‚ùå Error listing folder: {e}', 'error')
        return {'folders': [], 'sheets': []}

# ============ CERTIFICATE GENERATION ============

class RateLimiter:
    def __init__(self, max_per_min=50):
        self.max = max_per_min
        self.timestamps = []
        self.lock = threading.Lock()
    
    def wait(self):
        with self.lock:
            now = time.time()
            self.timestamps = [t for t in self.timestamps if now - t < 60]
            if len(self.timestamps) >= self.max:
                wait_time = 60 - (now - self.timestamps[0]) + 0.5
                add_log(f'‚è≥ Rate limit, waiting {wait_time:.0f}s...', 'warning')
                time.sleep(wait_time)
                self.timestamps = []
            self.timestamps.append(time.time())

def process_certificate(acc_idx, row_idx, row_data, rate_limiter):
    """Process one certificate"""
    if stop_flag.is_set():
        return False
    
    while pause_flag.is_set():
        time.sleep(0.5)
        if stop_flag.is_set():
            return False
    
    rate_limiter.wait()
    drive, docs, slides, sheets = get_services(acc_idx)
    
    config = state['config']
    variables = state['variables']
    
    # Detect if template is Slides or Docs
    template_type = config.get('template_type', 'doc')  # 'doc' or 'slide'
    
    # Get file name from name column
    name_col = config.get('name_column', '')
    if name_col:
        name_col_idx = column_to_index(name_col)
    else:
        # Fallback to first variable's column or column A
        if variables and variables[0].get('column'):
            name_col_idx = column_to_index(variables[0]['column'])
        else:
            name_col_idx = 0
    
    raw_name = row_data[name_col_idx] if len(row_data) > name_col_idx else f'Certificate_{row_idx}'
    
    # Clean the name
    file_name = clean_name(raw_name)
    
    state['current_name'] = file_name
    broadcast_state()
    
    doc_id = None
    
    # Use shared root folder as temp folder
    temp_folder = config.get('temp_folder_id') or SHARED_ROOT_FOLDER
    
    try:
        # 1. Copy template
        doc_id = drive.files().copy(
            fileId=config['template_doc_id'],
            body={'name': file_name, 'parents': [temp_folder]},
            supportsAllDrives=True,
            fields='id'
        ).execute()['id']
        
        time.sleep(0.3)
        
        # 2. Replace ALL variables
        requests = []
        for idx, var in enumerate(variables):
            placeholder = var['placeholder']
            
            if var['source'] == 'column':
                col_idx = column_to_index(var['column'])
                raw_value = row_data[col_idx] if len(row_data) > col_idx else ''
                # Always clean name values
                value = clean_name(raw_value)
            else:
                value = var.get('value', '')
            
            requests.append({
                'replaceAllText': {
                    'containsText': {'text': placeholder, 'matchCase': True},
                    'replaceText': str(value)
                }
            })
        
        if requests:
            if template_type == 'slide':
                # Use Slides API
                slides.presentations().batchUpdate(
                    presentationId=doc_id,
                    body={'requests': requests}
                ).execute()
            else:
                # Use Docs API
                docs.documents().batchUpdate(
                    documentId=doc_id,
                    body={'requests': requests}
                ).execute()
        
        # 3. Export as PDF
        pdf_data = drive.files().export(fileId=doc_id, mimeType='application/pdf').execute()
        
        # 4. Upload PDF
        pdf_file = drive.files().create(
            body={'name': f'{file_name}.pdf', 'parents': [config['target_folder_id']]},
            media_body=MediaIoBaseUpload(io.BytesIO(pdf_data), mimetype='application/pdf'),
            fields='webViewLink',
            supportsAllDrives=True
        ).execute()
        
        # 5. Delete temp doc (try multiple times)
        delete_success = False
        for attempt in range(3):
            try:
                time.sleep(0.5)  # Wait a bit before deleting
                drive.files().delete(fileId=doc_id, supportsAllDrives=True).execute()
                delete_success = True
                doc_id = None
                break
            except Exception as del_err:
                if attempt == 2:  # Last attempt
                    # Try to trash instead
                    try:
                        drive.files().update(fileId=doc_id, body={'trashed': True}, supportsAllDrives=True).execute()
                        doc_id = None
                    except:
                        add_log(f'‚ö†Ô∏è Could not delete temp doc: {str(del_err)[:80]}', 'warning')
        
        # 6. Update sheet with link
        link_col = config['link_column'].upper()
        
        # row_idx is now the actual row number in the sheet
        actual_row = row_idx
        
        sheets.spreadsheets().values().update(
            spreadsheetId=config['sheet_id'],
            range=f"{link_col}{actual_row}",
            valueInputOption='RAW',
            body={'values': [[pdf_file['webViewLink']]]}
        ).execute()
        
        # Track processed names
        with state_lock:
            state['processed_names'].add(file_name)
            state['completed'] += 1
        
        add_log(f'‚úÖ [{state["completed"]}/{state["total"]}] {file_name}', 'success')
        broadcast_state()
        
        return True
        
    except Exception as e:
        with state_lock:
            state['failed'] += 1
        add_log(f'‚ùå {file_name}: {str(e)[:100]}', 'error')
        
        if doc_id:
            try:
                drive.files().delete(fileId=doc_id, supportsAllDrives=True).execute()
            except:
                pass
        
        broadcast_state()
        return False

def account_worker(acc_idx, items, rate_limiter):
    """Worker for one account"""
    for row_idx, row_data in items:
        if stop_flag.is_set():
            break
        process_certificate(acc_idx, row_idx, row_data, rate_limiter)

def get_pending_rows():
    """Get rows that need certificates"""
    config = state['config']
    
    if not config['sheet_id']:
        return []
    
    try:
        _, _, _, sheets = get_services(0)
        
        # Determine range based on mode
        if config['range_mode'] == 'custom':
            range_start = int(config.get('range_start', 2))
            range_end = int(config.get('range_end', 1000))
            sheet_range = f'A{range_start}:Z{range_end}'
            start_row = range_start
            skip_header = False
        else:
            # All rows mode - start from row 2 (after header)
            sheet_range = 'A2:Z'
            start_row = 2
            skip_header = False
        
        result = sheets.spreadsheets().values().get(
            spreadsheetId=config['sheet_id'],
            range=sheet_range
        ).execute()
        
        rows = result.get('values', [])
        
        link_col_idx = column_to_index(config['link_column'])
        
        # Get name column from first variable
        variables = state.get('variables', [])
        if variables and variables[0].get('column'):
            name_col_idx = column_to_index(variables[0]['column'])
        else:
            name_col_idx = column_to_index('C')  # Default to C
        
        todo = []
        for i, row in enumerate(rows):
            has_link = len(row) > link_col_idx and row[link_col_idx] and row[link_col_idx].startswith('http')
            has_name = len(row) > name_col_idx and row[name_col_idx] and row[name_col_idx].strip()
            
            if has_name and not has_link:
                # Store actual row number in sheet (1-based)
                actual_row = start_row + i
                todo.append((actual_row, row))
        
        return todo
    except Exception as e:
        add_log(f'‚ùå Error reading sheet: {e}', 'error')
        return []

def retry_failed_certificates():
    """Retry generation for certificates that don't have links"""
    if state['retry_count'] >= state['max_retries']:
        add_log(f'‚ö†Ô∏è Reached maximum retry attempts ({state["max_retries"]})', 'warning')
        return False
    
    state['retry_count'] += 1
    add_log(f'üîÑ Starting retry attempt {state["retry_count"]}/{state["max_retries"]}...', 'info')
    
    # Get pending rows (those without links)
    todo = get_pending_rows()
    
    if not todo:
        add_log('‚úÖ No pending certificates to retry', 'success')
        return False
    
    add_log(f'üìù Found {len(todo)} certificates to retry', 'info')
    
    # Run generator with the pending items
    run_generator(todo, is_retry=True)
    
    return True

def run_generator(todo=None, is_retry=False):
    """Main generator function"""
    global state
    
    stop_flag.clear()
    pause_flag.clear()
    
    state['status'] = 'running'
    state['start_time'] = time.time()
    
    broadcast_state()
    add_log('üöÄ Starting certificate generation...', 'info')
    
    if not state['accounts_loaded']:
        if not load_service_accounts():
            state['status'] = 'idle'
            add_log('‚ùå Cannot start: No service accounts!', 'error')
            broadcast_state()
            return
    
    config = state['config']
    
    # Only require template, target folder, and sheet (temp folder uses shared root)
    if not all([config['template_doc_id'], config['target_folder_id'], config['sheet_id']]):
        state['status'] = 'idle'
        add_log('‚ùå Missing configuration! Please fill all required fields.', 'error')
        broadcast_state()
        return
    
    try:
        if todo is None:
            add_log('üìñ Reading spreadsheet...', 'info')
            todo = get_pending_rows()
        
        state['total'] = len(todo)
        state['completed'] = 0
        state['failed'] = 0
        
        add_log(f'üìù {len(todo)} certificates to generate', 'info')
        broadcast_state()
        
        if not todo:
            state['status'] = 'watching' if config['auto_watch'] else 'idle'
            add_log('‚úÖ No pending certificates.', 'success')
            broadcast_state()
            return
        
        # Distribute among accounts
        num_accounts = len(state['accounts'])
        batches = [[] for _ in range(num_accounts)]
        
        for idx, item in enumerate(todo):
            batches[idx % num_accounts].append(item)
        
        rate_limiters = [RateLimiter(50) for _ in range(num_accounts)]
        
        threads = []
        for acc_idx, batch in enumerate(batches):
            if batch:
                add_log(f'üë§ Account {acc_idx}: {len(batch)} items', 'info')
                t = threading.Thread(target=account_worker, args=(acc_idx, batch, rate_limiters[acc_idx]))
                t.start()
                threads.append(t)
        
        for t in threads:
            t.join()
        
        elapsed = time.time() - state['start_time']
        rate = state['completed'] / (elapsed / 60) if elapsed > 0 else 0
        
        add_log(f'üéâ Batch completed! {state["completed"]} certificates in {elapsed/60:.1f} minutes ({rate:.0f}/min)', 'success')
        
        # Check if there are failed certificates and retry
        if state['failed'] > 0 and not is_retry:
            add_log(f'‚ö†Ô∏è {state["failed"]} certificates failed. Preparing to retry...', 'warning')
            time.sleep(2)  # Wait 2 seconds before retry
            
            # Reset retry counter for new batch
            state['retry_count'] = 0
            
            # Try to retry failed certificates
            retry_success = retry_failed_certificates()
            
            # If retry was performed, the status will be set by the retry run
            if not retry_success:
                state['status'] = 'watching' if config['auto_watch'] else 'completed'
        else:
            state['status'] = 'watching' if config['auto_watch'] else 'completed'
            if is_retry:
                add_log(f'‚úÖ Retry completed. Total completed: {state["completed"]}, Failed: {state["failed"]}', 'success')
        
        broadcast_state()
        
    except Exception as e:
        state['status'] = 'idle'
        add_log(f'üí• Error: {str(e)}', 'error')
        broadcast_state()

# ============ AUTO WATCHER ============

def watcher_loop():
    """Watch for new entries and auto-generate"""
    add_log('üëÅÔ∏è Auto-watch started. Checking every {}s...'.format(state['config']['watch_interval']), 'info')
    
    while not watch_stop_flag.is_set():
        if state['status'] not in ['running', 'paused']:
            # Check for new entries
            todo = get_pending_rows()
            
            if todo:
                add_log(f'üÜï Found {len(todo)} new entries!', 'info')
                state['status'] = 'running'
                run_generator(todo)
            
        # Wait for interval
        for _ in range(state['config']['watch_interval']):
            if watch_stop_flag.is_set():
                break
            time.sleep(1)
    
    add_log('üëÅÔ∏è Auto-watch stopped', 'warning')

def start_watcher():
    global watcher_thread
    
    if watcher_thread and watcher_thread.is_alive():
        return
    
    watch_stop_flag.clear()
    watcher_thread = threading.Thread(target=watcher_loop, daemon=True)
    watcher_thread.start()
    state['config']['auto_watch'] = True
    state['status'] = 'watching'
    broadcast_state()

def stop_watcher():
    watch_stop_flag.set()
    state['config']['auto_watch'] = False
    if state['status'] == 'watching':
        state['status'] = 'idle'
    broadcast_state()

# ============ DRIVE BROWSER ============

# Shared Drive folder ID (the root folder shared with all service accounts)
SHARED_ROOT_FOLDER = '0AHlyd4Og76tkUk9PVA'

def list_drive_files(folder_id='root', file_type='all'):
    """List files in a Google Drive folder"""
    drive, _, _, _ = get_services(0)
    if not drive:
        return []
    
    try:
        # Use shared root folder if 'root' is requested
        if folder_id == 'root':
            folder_id = SHARED_ROOT_FOLDER
        
        parent_query = f"'{folder_id}' in parents"
        
        # Determine what to show based on type
        if file_type == 'folder':
            # Show only folders
            mime_query = "mimeType='application/vnd.google-apps.folder'"
        elif file_type == 'doc':
            # Show folders, Google Docs, and Google Slides
            mime_query = "(mimeType='application/vnd.google-apps.folder' or mimeType='application/vnd.google-apps.document' or mimeType='application/vnd.google-apps.presentation')"
        elif file_type == 'sheet':
            # Show folders and Google Sheets
            mime_query = "(mimeType='application/vnd.google-apps.folder' or mimeType='application/vnd.google-apps.spreadsheet')"
        else:
            # Show all
            mime_query = "mimeType != 'application/vnd.google-apps.form'"
        
        query = f"{parent_query} and {mime_query} and trashed=false"
        
        results = drive.files().list(
            q=query,
            fields="files(id, name, mimeType)",
            orderBy="folder,name",
            pageSize=100,
            supportsAllDrives=True,
            includeItemsFromAllDrives=True
        ).execute()
        
        files = []
        for f in results.get('files', []):
            files.append({
                'id': f['id'],
                'name': f['name'],
                'mimeType': f['mimeType'],
                'isFolder': f['mimeType'] == 'application/vnd.google-apps.folder'
            })
        
        # Sort: folders first, then by name
        files.sort(key=lambda x: (not x['isFolder'], x['name'].lower()))
        
        return files
        
    except Exception as e:
        add_log(f'‚ùå Error listing drive: {e}', 'error')
        return []

def get_sheet_columns(sheet_id):
    """Get column headers from first row of sheet"""
    try:
        _, _, _, sheets = get_services(0)
        result = sheets.spreadsheets().values().get(
            spreadsheetId=sheet_id,
            range='1:1'  # First row only
        ).execute()
        
        headers = result.get('values', [[]])[0]
        columns = []
        for idx, header in enumerate(headers):
            col_letter = ''
            n = idx
            while n >= 0:
                col_letter = chr(n % 26 + ord('A')) + col_letter
                n = n // 26 - 1
            columns.append({
                'letter': col_letter,
                'name': header.strip() if header else f'Column {col_letter}',
                'index': idx
            })
        add_log(f'üìä Loaded {len(columns)} columns from sheet', 'info')
        return columns
    except Exception as e:
        import traceback
        print(f"Error reading sheet columns: {e}")
        print(traceback.format_exc())
        add_log(f'‚ö†Ô∏è Could not read sheet headers: {str(e)[:100]}', 'warning')
        return []

def auto_detect_name_column(columns):
    """Auto-detect column with name based on header"""
    if not columns:
        return ''
    
    # Search for column with name-like headers
    name_keywords = ['ÿßÿ≥ŸÖ', 'ÿßŸÑÿßÿ≥ŸÖ', 'name', 'ÿßŸÑÿ•ÿ≥ŸÖ', 'ÿ£ÿ≥ŸÖ', 'ÿßÔªªÿ≥ŸÖ']
    
    for col in columns:
        header_lower = col['name'].lower().strip()
        for keyword in name_keywords:
            if keyword in header_lower:
                add_log(f'‚úÖ Auto-detected name column: {col["letter"]} ({col["name"]})', 'success')
                return col['letter']
    
    # Fallback to first column
    if columns:
        add_log(f'‚ö†Ô∏è No name column found, using first column: {columns[0]["letter"]}', 'warning')
        return columns[0]['letter']
    
    return 'A'

def find_or_create_link_column(sheet_id):
    """Find 'ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©' column or create it as last column"""
    try:
        _, _, _, sheets = get_services(0)
        
        # Get all rows to find actual last column with data
        result = sheets.spreadsheets().values().get(
            spreadsheetId=sheet_id,
            range='1:100'  # Check first 100 rows
        ).execute()
        
        rows = result.get('values', [])
        if not rows:
            # Empty sheet - start at column A
            sheets.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range='A1',
                valueInputOption='RAW',
                body={'values': [['ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©']]}
            ).execute()
            add_log('üîó Created link column "ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©" at A', 'success')
            return 'A'
        
        headers = rows[0] if rows else []
        
        # Search for existing "ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©" column
        link_column_names = ['ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©', 'ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØŸá', 'Certificate Link', 'certificate_link', 'Link']
        for idx, header in enumerate(headers):
            header_clean = header.strip().lower() if header else ''
            for name in link_column_names:
                if name.lower() in header_clean or header_clean in name.lower():
                    # Found! Calculate column letter
                    col_letter = ''
                    n = idx
                    while n >= 0:
                        col_letter = chr(n % 26 + ord('A')) + col_letter
                        n = n // 26 - 1
                    add_log(f'üîó Found link column "{header}" at {col_letter}', 'info')
                    return col_letter
        
        # Not found - find the last non-empty column across all rows
        max_col = 0
        for row in rows:
            # Find last non-empty cell in this row
            for i in range(len(row) - 1, -1, -1):
                if row[i] and str(row[i]).strip():
                    max_col = max(max_col, i)
                    break
        
        # Add column after last used column
        next_col_idx = max_col + 1
        col_letter = ''
        n = next_col_idx
        while n >= 0:
            col_letter = chr(n % 26 + ord('A')) + col_letter
            n = n // 26 - 1
        
        # Write header with name "ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©"
        sheets.spreadsheets().values().update(
            spreadsheetId=sheet_id,
            range=f'{col_letter}1',
            valueInputOption='RAW',
            body={'values': [['ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©']]}
        ).execute()
        
        add_log(f'üîó Created link column "ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ¥ŸáÿßÿØÿ©" at {col_letter}', 'success')
        return col_letter
        
    except Exception as e:
        import traceback
        print(f"Error in find_or_create_link_column: {e}")
        print(traceback.format_exc())
        add_log(f'‚ö†Ô∏è Could not find/create link column: {str(e)[:100]}', 'warning')
        return 'O'  # Default fallback

# ============ ROUTES ============

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/drive/list')
def api_drive_list():
    """API to list files in Google Drive"""
    folder_id = request.args.get('folder_id', 'root')
    file_type = request.args.get('type', 'all')
    
    files = list_drive_files(folder_id, file_type)
    return jsonify({'files': files})

@app.route('/api/sheet/columns')
def api_sheet_columns():
    """Get column headers from sheet"""
    sheet_id = request.args.get('sheet_id', '')
    if not sheet_id:
        return jsonify({'columns': []})
    
    columns = get_sheet_columns(sheet_id)
    return jsonify({'columns': columns})

@app.route('/api/state')
def get_state():
    return jsonify({
        'status': state['status'],
        'total': state['total'],
        'completed': state['completed'],
        'failed': state['failed'],
        'retry_count': state.get('retry_count', 0),
        'max_retries': state.get('max_retries', 2),
        'config': state['config'],
        'variables': state['variables'],
        'columns': state.get('columns', []),
        'accounts_count': len(state['accounts']),
        'available_sheets': state['available_sheets'],
        'logs': state['logs'][-50:]
    })

@app.route('/api/config', methods=['POST'])
def save_config():
    data = request.json
    
    # Template - now receives ID directly
    state['config']['template_doc_id'] = data.get('template_doc_id', '')
    state['config']['template_doc_name'] = data.get('template_doc_name', '')
    
    # Auto-detect template type from Drive API
    if state['config']['template_doc_id']:
        try:
            drive, _, _, _ = get_services(0)
            file_info = drive.files().get(
                fileId=state['config']['template_doc_id'], 
                fields='mimeType',
                supportsAllDrives=True
            ).execute()
            mime_type = file_info.get('mimeType', '')
            
            if 'presentation' in mime_type:
                state['config']['template_type'] = 'slide'
                add_log('üìä Detected template type: Google Slides', 'info')
            elif 'document' in mime_type:
                state['config']['template_type'] = 'doc'
                add_log('üìÑ Detected template type: Google Docs', 'info')
            else:
                state['config']['template_type'] = 'doc'  # Default
                add_log(f'‚ö†Ô∏è Unknown template type: {mime_type}, defaulting to Docs', 'warning')
        except Exception as e:
            state['config']['template_type'] = 'doc'  # Default on error
            add_log(f'‚ö†Ô∏è Could not detect template type: {str(e)[:50]}', 'warning')
    else:
        state['config']['template_type'] = 'doc'
    
    # Target folder
    state['config']['target_folder_id'] = data.get('target_folder_id', '')
    state['config']['target_folder_name'] = data.get('target_folder_name', '')
    
    # Temp folder
    state['config']['temp_folder_id'] = data.get('temp_folder_id', '')
    state['config']['temp_folder_name'] = data.get('temp_folder_name', '')
    
    # Sheet
    state['config']['sheet_id'] = data.get('sheet_id', '')
    state['config']['sheet_name'] = data.get('sheet_name', '')
    
    # Load columns if sheet changed
    if state['config']['sheet_id']:
        state['columns'] = get_sheet_columns(state['config']['sheet_id'])
        # Auto-detect or create link column
        state['config']['link_column'] = find_or_create_link_column(state['config']['sheet_id'])
        # Auto-detect name column
        state['config']['name_column'] = auto_detect_name_column(state['columns'])
    else:
        state['columns'] = []
        state['config']['link_column'] = 'O'
        state['config']['name_column'] = ''
    
    state['config']['range_mode'] = data.get('range_mode', 'all')
    state['config']['range_start'] = int(data.get('range_start', 2))
    state['config']['range_end'] = int(data.get('range_end', 1000))
    state['config']['watch_interval'] = int(data.get('watch_interval', 30))
    
    add_log('‚öôÔ∏è Configuration saved', 'info')
    
    # Auto-detect single variable from template
    if state['config']['template_doc_id']:
        template_type = state['config'].get('template_type', 'doc')
        detected = detect_template_variables(state['config']['template_doc_id'], template_type)
        if detected:
            # Use first detected variable as the name variable
            first_var = detected[0]
            name_col = state['config'].get('name_column', '')
            state['variables'] = [{
                'placeholder': first_var,
                'source': 'column',
                'column': name_col if name_col else 'A',
                'description': 'ÿßŸÑÿßÿ≥ŸÖ'
            }]
            add_log(f'üîç Detected variable: {first_var} ‚Üí Column {name_col or "A"}', 'info')
    
    return jsonify({'success': True, 'config': state['config'], 'variables': state['variables'], 'columns': state['columns']})

def detect_template_variables(template_id, template_type='doc'):
    """Detect {{VARIABLE}} patterns in template document or presentation"""
    try:
        drive, docs, slides, _ = get_services(0)
        
        full_text = ''
        
        if template_type == 'slide':
            # Get Slides presentation
            presentation = slides.presentations().get(presentationId=template_id).execute()
            
            # Extract text from all slides
            for slide in presentation.get('slides', []):
                for element in slide.get('pageElements', []):
                    if 'shape' in element:
                        shape = element['shape']
                        if 'text' in shape:
                            for text_elem in shape['text'].get('textElements', []):
                                if 'textRun' in text_elem:
                                    full_text += text_elem['textRun'].get('content', '')
        else:
            # Get Docs document
            doc = docs.documents().get(documentId=template_id).execute()
            
            # Extract all text from document
            content = doc.get('body', {}).get('content', [])
            
            for element in content:
                if 'paragraph' in element:
                    for elem in element['paragraph'].get('elements', []):
                        if 'textRun' in elem:
                            full_text += elem['textRun'].get('content', '')
        
        # Find all <<VARIABLE>> patterns (Arabic and English)
        import re
        # Match <<text>> where text can be Arabic, English, numbers, spaces, or underscores
        variables = re.findall(r'<<([\u0600-\u06FFa-zA-Z0-9_\s]+)>>', full_text)
        
        # Return unique variables with <<>> format
        unique_vars = list(dict.fromkeys(['<<' + v.strip() + '>>' for v in variables]))
        return unique_vars
        
    except Exception as e:
        add_log(f'‚ö†Ô∏è Could not read template: {str(e)[:50]}', 'warning')
        return []

@app.route('/api/detect-variables', methods=['POST'])
def api_detect_variables():
    """Manually trigger variable detection"""
    data = request.json or {}
    
    # Get template URL from request or from config
    template_url = data.get('template_url', '')
    if template_url:
        template_id = extract_id_from_url(template_url)
    else:
        template_id = state['config'].get('template_doc_id', '')
    
    if not template_id:
        return jsonify({'error': 'No template configured'}), 400
    
    detected = detect_template_variables(template_id)
    if detected:
        # Update variables
        existing_placeholders = {v['placeholder']: v for v in state['variables']}
        new_variables = []
        for placeholder in detected:
            if placeholder in existing_placeholders:
                new_variables.append(existing_placeholders[placeholder])
            else:
                new_variables.append({
                    'placeholder': placeholder,
                    'source': 'column',
                    'column': '',
                    'description': ''
                })
        state['variables'] = new_variables
        add_log(f'üîç Detected {len(detected)} variables', 'success')
        # Return detected as list of strings (placeholders only)
        return jsonify({'success': True, 'variables': detected})
    
    return jsonify({'success': False, 'error': 'No variables found'})

@app.route('/api/variables', methods=['POST'])
def save_variables():
    state['variables'] = request.json.get('variables', [])
    add_log(f'üìù Saved {len(state["variables"])} variables', 'info')
    return jsonify({'success': True})

@app.route('/api/cleanup-config', methods=['POST'])
def save_cleanup_config():
    data = request.json
    state['config']['cleanup'] = {
        'enabled': data.get('enabled', True),
        'remove_words': data.get('remove_words', []),
        'remove_before_slash': data.get('remove_before_slash', True),
        'remove_alef': data.get('remove_alef', True),
        'trim_spaces': data.get('trim_spaces', True)
    }
    add_log(f'üßπ Saved cleanup config ({len(state["config"]["cleanup"]["remove_words"])} words)', 'info')
    return jsonify({'success': True})

@app.route('/api/start', methods=['POST'])
def start_generation():
    global generator_thread
    
    if state['status'] == 'running':
        return jsonify({'error': 'Already running'}), 400
    
    # Reset retry counter when starting fresh
    state['retry_count'] = 0
    
    generator_thread = threading.Thread(target=run_generator)
    generator_thread.start()
    
    return jsonify({'success': True})

@app.route('/api/pause', methods=['POST'])
def pause_generation():
    if pause_flag.is_set():
        pause_flag.clear()
        state['status'] = 'running'
        add_log('‚ñ∂Ô∏è Resumed', 'info')
    else:
        pause_flag.set()
        state['status'] = 'paused'
        add_log('‚è∏Ô∏è Paused', 'warning')
    
    broadcast_state()
    return jsonify({'success': True, 'paused': pause_flag.is_set()})

@app.route('/api/stop', methods=['POST'])
def stop_generation():
    stop_flag.set()
    pause_flag.clear()
    stop_watcher()
    state['status'] = 'idle'
    add_log('‚èπÔ∏è Stopped', 'warning')
    broadcast_state()
    return jsonify({'success': True})

@app.route('/api/auto-watch', methods=['POST'])
def toggle_auto_watch():
    data = request.json
    enable = data.get('enable', False)
    
    if enable:
        start_watcher()
        add_log('üëÅÔ∏è Auto-watch enabled', 'success')
    else:
        stop_watcher()
        add_log('üëÅÔ∏è Auto-watch disabled', 'warning')
    
    return jsonify({'success': True, 'watching': state['config']['auto_watch']})

@app.route('/api/reload-accounts', methods=['POST'])
def reload_accounts():
    state['accounts'] = []
    state['accounts_loaded'] = False
    load_service_accounts()
    return jsonify({'success': True, 'count': len(state['accounts'])})

# ============ SOCKETIO ============

@socketio.on('connect')
def handle_connect():
    emit('state_update', {
        'status': state['status'],
        'total': state['total'],
        'completed': state['completed'],
        'failed': state['failed'],
        'current_name': state['current_name'],
        'watching': state['config']['auto_watch'],
    })

# ============ MAIN ============

if __name__ == '__main__':
    import sys
    
    port = int(sys.argv[1]) if len(sys.argv) > 1 else 5000
    
    print("\n" + "="*50)
    print("  üìú Certificate Generator Dashboard v2")
    print("="*50)
    print(f"\n  Open in browser: http://0.0.0.0:{port}\n")
    
    load_service_accounts()
    
    # Production mode (no debug)
    socketio.run(app, host='0.0.0.0', port=port, debug=False)
